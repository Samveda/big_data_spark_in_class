![GitHub Logo](https://s3.ap-south-1.amazonaws.com/greyatom-social/GreyAtom-logo.png)

# APACHE SPARK

Apache Spark is a lightning-fast cluster computing technology, designed for fast computation. It is based on Hadoop MapReduce and it extends the MapReduce model to efficiently use it for more types of computations, which includes interactive queries and stream processing. The main feature of Spark is its in-memory cluster computing that increases the processing speed of an application. 


## At a glance
* In Class Instruction: 4 Hours
  * In Class code along Dataset: customers
  
  
## In Class Activity

* Installation of Spark
* Hands-on exercise with datasets


## Pre Reads

1. [Spark](https://spark.apache.org/) is a fast and general engine for large-scale data processing.
2. [Hortonworks](https://hortonworks.com/) has an introductory [tutorial](https://hortonworks.com/apache/spark/).

## Learning Objectives

- Understand what is Spark and where does it fit in the Hadoop ecosystem
- Components of Spark
- Extending Spark where required to achieve different objectives
- Running and Executing a Spark script

## Agenda
- Why we need Spark
- Spark v/s Mapreduce
- RDD Processing
- What is Transform and Action

## Slides
[Spark]()


## Post Reads
1. [Apache Spark](https://medium.com/@aristo_alex/apache-spark-for-beginners-d3b3791e259e) for beginners
2. Research Paper on [Spark](https://spark.apache.org/research.html)
